"""
Security Requirements Analyzer Service
Analyzes user stories to generate security requirements, threats, and abuse cases
"""
import os
import json
import time
from typing import Dict, Any, List, Optional, Callable

from dotenv import load_dotenv
load_dotenv()  # Load .env file

# Try multiple AI providers
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


class SecurityRequirementsAnalyzer:
    """Analyzes user stories to generate security requirements using AI"""

    # Default prompt instructions that can be customized via settings
    DEFAULT_ABUSE_CASE_PROMPT = """Generate 5-7 realistic abuse cases. Each abuse case must have:
- id: Unique identifier (AC-001, AC-002, etc.)
- threat: Clear title of the abuse scenario
- actor: Who would do this (Malicious User, Disgruntled Employee, Competitor, Fraudster, Bot)
- description: Realistic scenario describing how this abuse would occur through normal application use
- impact: Critical/High/Medium/Low
- likelihood: High/Medium/Low
- attack_vector: How the abuse is carried out
- stride_category: Spoofing/Tampering/Repudiation/Information Disclosure/Denial of Service/Elevation of Privilege

Focus on REALISTIC business abuse scenarios, not technical hacking attacks. Examples:
- Account sharing to avoid subscription fees
- Promotional code abuse and stacking
- Refund/chargeback fraud
- Data scraping by competitors
- Insider data theft before resignation
- Fake reviews or ratings manipulation"""

    DEFAULT_SECURITY_REQ_PROMPT = """Generate 10-15 actionable security requirements. Each requirement must have:
- id: Unique identifier (SR-001, SR-002, etc.)
- requirement: Clear, actionable security control statement
- priority: Critical/High/Medium
- category: Authentication/Authorization/Input Validation/Cryptography/Logging/Rate Limiting/API Security/Data Protection/Session Management/Error Handling
- rationale: Why this requirement is needed and implementation guidance
- acceptance_criteria: Bullet-pointed testable criteria (use \\n for line breaks, start each with â€¢)

Requirements should be SPECIFIC to the user story functionality, not generic security controls.
Map requirements to relevant compliance standards (OWASP, CWE, PCI-DSS, GDPR) where applicable."""

    STRIDE_CATEGORIES = [
        {"id": "S", "name": "Spoofing", "description": "Pretending to be something or someone else"},
        {"id": "T", "name": "Tampering", "description": "Modifying data or code"},
        {"id": "R", "name": "Repudiation", "description": "Claiming to not have performed an action"},
        {"id": "I", "name": "Information Disclosure", "description": "Exposing information to unauthorized users"},
        {"id": "D", "name": "Denial of Service", "description": "Deny or degrade service to users"},
        {"id": "E", "name": "Elevation of Privilege", "description": "Gain capabilities without authorization"},
    ]

    COMPLIANCE_STANDARDS = {
        "OWASP ASVS": {
            "V1": "Architecture, Design and Threat Modeling",
            "V2": "Authentication",
            "V3": "Session Management",
            "V4": "Access Control",
            "V5": "Validation, Sanitization and Encoding",
            "V6": "Stored Cryptography",
            "V7": "Error Handling and Logging",
            "V8": "Data Protection",
            "V9": "Communication",
            "V10": "Malicious Code",
            "V11": "Business Logic",
            "V12": "Files and Resources",
            "V13": "API and Web Service",
            "V14": "Configuration",
        },
        "PCI-DSS": {
            "Req 1": "Install and maintain network security controls",
            "Req 2": "Apply secure configurations",
            "Req 3": "Protect stored account data",
            "Req 4": "Protect cardholder data with strong cryptography",
            "Req 5": "Protect systems from malicious software",
            "Req 6": "Develop and maintain secure systems",
            "Req 7": "Restrict access to system components",
            "Req 8": "Identify users and authenticate access",
            "Req 9": "Restrict physical access",
            "Req 10": "Log and monitor access",
            "Req 11": "Test security systems regularly",
            "Req 12": "Support information security with policies",
        },
    }

    def __init__(self, api_key: Optional[str] = None, provider: str = "openai",
                 custom_abuse_case_prompt: Optional[str] = None,
                 custom_security_req_prompt: Optional[str] = None,
                 feedback_fetcher: Optional[Callable] = None):
        """Initialize the analyzer with AI provider and optional custom prompts

        Args:
            api_key: API key for the AI provider
            provider: AI provider to use (openai, anthropic)
            custom_abuse_case_prompt: Custom prompt for abuse case generation
            custom_security_req_prompt: Custom prompt for security requirement generation
            feedback_fetcher: Optional callable that fetches feedback from database
                             Should return dict with keys: abuse_case_positive, abuse_case_negative,
                             security_requirement_positive, security_requirement_negative
        """
        self.provider = provider
        self.client = None
        self.model = None
        self.feedback_fetcher = feedback_fetcher

        # Store custom prompts (use defaults if not provided)
        self.abuse_case_prompt = custom_abuse_case_prompt or self.DEFAULT_ABUSE_CASE_PROMPT
        self.security_req_prompt = custom_security_req_prompt or self.DEFAULT_SECURITY_REQ_PROMPT

        print(f"[SecurityAnalyzer] Initializing with provider={provider}, api_key={'SET' if api_key else 'NOT SET'}")
        print(f"[SecurityAnalyzer] OPENAI_AVAILABLE={OPENAI_AVAILABLE}, ANTHROPIC_AVAILABLE={ANTHROPIC_AVAILABLE}")

        # Try primary provider first
        if provider == "anthropic" and ANTHROPIC_AVAILABLE:
            key = api_key or os.getenv("ANTHROPIC_API_KEY")
            if key:
                self.client = anthropic.Anthropic(api_key=key)
                self.model = "claude-sonnet-4-20250514"  # Use Sonnet for faster analysis
                print(f"[SecurityAnalyzer] Using Anthropic with model={self.model}")
            else:
                print("[SecurityAnalyzer] Anthropic selected but no API key found, trying OpenAI fallback")
        elif provider == "openai" and OPENAI_AVAILABLE:
            key = api_key or os.getenv("OPENAI_API_KEY")
            if key:
                self.client = OpenAI(api_key=key)
                self.model = "gpt-4o"
                print(f"[SecurityAnalyzer] Using OpenAI with model={self.model}")
            else:
                print("[SecurityAnalyzer] OpenAI selected but no API key found")

        # Fallback: If primary provider failed, try the other one
        if self.client is None:
            # Try OpenAI as fallback
            if OPENAI_AVAILABLE:
                openai_key = os.getenv("OPENAI_API_KEY")
                if openai_key:
                    self.client = OpenAI(api_key=openai_key)
                    self.model = "gpt-4o"
                    self.provider = "openai"
                    print(f"[SecurityAnalyzer] Fallback to OpenAI with model={self.model}")
            # Try Anthropic as fallback
            if self.client is None and ANTHROPIC_AVAILABLE:
                anthropic_key = os.getenv("ANTHROPIC_API_KEY")
                if anthropic_key:
                    self.client = anthropic.Anthropic(api_key=anthropic_key)
                    self.model = "claude-sonnet-4-20250514"  # Use Sonnet for faster analysis
                    self.provider = "anthropic"
                    print(f"[SecurityAnalyzer] Fallback to Anthropic with model={self.model}")

        if self.client is None:
            print(f"[SecurityAnalyzer] No AI provider available, will use template analysis")

    def analyze_story(self, story: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze a user story for security concerns

        Args:
            story: Dict with title, description, acceptance_criteria

        Returns:
            Dict with abuse_cases, stride_threats, security_requirements, risk_score
        """
        start_time = time.time()

        title = story.get("title", "")
        description = story.get("description", "")
        acceptance_criteria = story.get("acceptance_criteria", "")

        # Try AI analysis first with retries
        if self.client:
            print(f"[SecurityAnalyzer] Using AI analysis with {self.provider}/{self.model}")
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    result = self._ai_analyze(title, description, acceptance_criteria)
                    result["analysis_duration_ms"] = int((time.time() - start_time) * 1000)
                    result["ai_model_used"] = self.model
                    print(f"[SecurityAnalyzer] AI analysis completed: {len(result.get('abuse_cases', []))} abuse cases, {len(result.get('security_requirements', []))} requirements")
                    return result
                except Exception as e:
                    error_msg = str(e)
                    # Retry on network/connection errors
                    if attempt < max_retries - 1 and ("connection" in error_msg.lower() or "timeout" in error_msg.lower() or "incomplete" in error_msg.lower() or "peer closed" in error_msg.lower()):
                        print(f"[SecurityAnalyzer] AI analysis attempt {attempt + 1} failed: {e}, retrying...")
                        time.sleep(2)  # Brief pause before retry
                        continue
                    print(f"[SecurityAnalyzer] AI analysis failed after {attempt + 1} attempts: {e}, falling back to template analysis")
                    import traceback
                    traceback.print_exc()
                    break
        else:
            print(f"[SecurityAnalyzer] No AI client available, using template analysis")

        # Fallback to template-based analysis
        result = self._template_analyze(title, description, acceptance_criteria)
        result["analysis_duration_ms"] = int((time.time() - start_time) * 1000)
        result["ai_model_used"] = "template"
        print(f"[SecurityAnalyzer] Template analysis completed: {len(result.get('abuse_cases', []))} abuse cases, {len(result.get('security_requirements', []))} requirements")
        return result

    def _ai_analyze(self, title: str, description: str, acceptance_criteria: str) -> Dict[str, Any]:
        """Use AI to analyze the user story"""
        prompt = self._build_analysis_prompt(title, description, acceptance_criteria)

        if self.provider == "anthropic":
            # Use non-streaming API call (more stable than streaming)
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4096,  # Reduced for faster response
                messages=[{"role": "user", "content": prompt}]
            )
            content = response.content[0].text
        else:  # OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                max_tokens=4096,  # Reduced for faster response
                messages=[
                    {"role": "system", "content": "You are a security architect. Generate concise, actionable security analysis. Return only valid JSON."},
                    {"role": "user", "content": prompt}
                ]
            )
            content = response.choices[0].message.content

        # Parse JSON from response
        try:
            # Try to extract JSON from the response
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                json_str = content[json_start:json_end]
                result = json.loads(json_str)
                return self._validate_and_enhance_result(result)
        except json.JSONDecodeError:
            pass

        # If JSON parsing fails, return template analysis
        return self._template_analyze(title, description, acceptance_criteria)

    def _build_analysis_prompt(self, title: str, description: str, acceptance_criteria: str) -> str:
        """Build the prompt for AI analysis - generates clean, structured security analysis
        Includes feedback examples for in-context learning when available."""
        ac_section = f"\nAcceptance Criteria: {acceptance_criteria}" if acceptance_criteria else ""

        # Build feedback examples section if feedback is available
        feedback_section = self._build_feedback_section()

        return f"""You are an expert application security analyst. Analyze the following user story for security threats, abuse cases, and generate security requirements.

**User Story Title:** {title}
**Description:** {description}{ac_section}

{self.abuse_case_prompt}

{self.security_req_prompt}
{feedback_section}
Return ONLY valid JSON with this exact structure:
{{
  "abuse_cases": [
    {{"id": "AC-001", "threat": "Abuse scenario title", "actor": "Who does this", "description": "How the abuse occurs", "impact": "High", "likelihood": "Medium", "attack_vector": "How it's carried out", "stride_category": "Information Disclosure"}}
  ],
  "stride_threats": [
    {{"category": "Spoofing", "threat": "Threat name", "description": "Detailed description", "risk_level": "High"}}
  ],
  "security_requirements": [
    {{"id": "SR-001", "requirement": "Actionable requirement statement", "priority": "Critical", "category": "Authentication", "rationale": "Why this is needed", "acceptance_criteria": "â€¢ Specific testable criterion 1\\nâ€¢ Specific testable criterion 2\\nâ€¢ Specific testable criterion 3"}}
  ],
  "risk_score": 65
}}

Generate at least 5 abuse cases, 6 STRIDE threats, and 10 security requirements. Be SPECIFIC to this user story, not generic."""

    def _build_feedback_section(self) -> str:
        """Build the feedback examples section for in-context learning.
        Fetches good and bad examples from the database to guide AI output."""
        if not self.feedback_fetcher:
            return ""

        try:
            feedback = self.feedback_fetcher()
            if not feedback:
                return ""

            sections = []

            # Abuse case examples
            abuse_positive = feedback.get("abuse_case_positive", [])
            abuse_negative = feedback.get("abuse_case_negative", [])

            if abuse_positive or abuse_negative:
                sections.append("\n## FEEDBACK-BASED GUIDANCE FOR ABUSE CASES:")

                if abuse_positive:
                    sections.append("\n**GOOD abuse case examples (generate similar quality):**")
                    for i, example in enumerate(abuse_positive[:3], 1):  # Limit to 3 examples
                        content = example.get("content", {})
                        sections.append(f"""
Example {i} (ðŸ‘ Well-received):
- Title: {content.get('title') or content.get('threat', 'N/A')}
- Actor: {content.get('actor') or content.get('threat_actor', 'N/A')}
- Description: {content.get('description', 'N/A')[:200]}...
- Impact: {content.get('impact', 'N/A')}""")

                if abuse_negative:
                    sections.append("\n**AVOID these patterns (marked as poor quality):**")
                    for i, example in enumerate(abuse_negative[:2], 1):  # Limit to 2 examples
                        content = example.get("content", {})
                        comment = example.get("comment", "")
                        sections.append(f"""
Anti-Example {i} (ðŸ‘Ž Avoid):
- Title: {content.get('title') or content.get('threat', 'N/A')}
- Why it's poor: {comment if comment else 'Too generic or unrealistic'}""")

            # Security requirement examples
            req_positive = feedback.get("security_requirement_positive", [])
            req_negative = feedback.get("security_requirement_negative", [])

            if req_positive or req_negative:
                sections.append("\n## FEEDBACK-BASED GUIDANCE FOR SECURITY REQUIREMENTS:")

                if req_positive:
                    sections.append("\n**GOOD security requirement examples (generate similar quality):**")
                    for i, example in enumerate(req_positive[:3], 1):
                        content = example.get("content", {})
                        sections.append(f"""
Example {i} (ðŸ‘ Well-received):
- ID: {content.get('id', 'N/A')}
- Requirement: {content.get('requirement') or content.get('text', 'N/A')}
- Category: {content.get('category', 'N/A')}
- Priority: {content.get('priority', 'N/A')}
- Acceptance Criteria: {(content.get('acceptance_criteria', 'N/A'))[:150]}...""")

                if req_negative:
                    sections.append("\n**AVOID these patterns (marked as poor quality):**")
                    for i, example in enumerate(req_negative[:2], 1):
                        content = example.get("content", {})
                        comment = example.get("comment", "")
                        sections.append(f"""
Anti-Example {i} (ðŸ‘Ž Avoid):
- Requirement: {content.get('requirement') or content.get('text', 'N/A')}
- Why it's poor: {comment if comment else 'Too vague or not actionable'}""")

            if sections:
                return "\n".join(sections) + "\n"

        except Exception as e:
            print(f"[SecurityAnalyzer] Error building feedback section: {e}")

        return ""

    def _template_analyze(self, title: str, description: str, acceptance_criteria: str) -> Dict[str, Any]:
        """Fallback when AI is not available - returns minimal placeholder data"""
        # Return minimal data indicating AI is required for proper analysis
        return {
            "abuse_cases": [
                {
                    "id": "AC-001",
                    "threat": "AI Analysis Required",
                    "actor": "N/A",
                    "description": "Configure AI provider (OpenAI or Anthropic) in settings to generate realistic abuse cases specific to this user story.",
                    "impact": "N/A",
                    "likelihood": "N/A",
                    "attack_vector": "N/A",
                    "stride_category": "N/A"
                }
            ],
            "stride_threats": [],
            "security_requirements": [
                {
                    "id": "SR-001",
                    "requirement": "AI Analysis Required",
                    "priority": "N/A",
                    "category": "Configuration",
                    "rationale": "Configure AI provider (OpenAI or Anthropic) in settings to generate actionable security requirements specific to this user story.",
                    "acceptance_criteria": "â€¢ Configure OpenAI or Anthropic API key in Settings\nâ€¢ Re-analyze this user story to generate specific requirements"
                }
            ],
            "risk_score": 0,
            "risk_factors": [],
            "ai_required": True,
            "message": "AI provider not configured. Please configure OpenAI or Anthropic API key in settings for full analysis."
        }

    def _legacy_template_analyze(self, title: str, description: str, acceptance_criteria: str) -> Dict[str, Any]:
        """DEPRECATED: Legacy template-based analysis - kept for reference only"""
        full_text = f"{title} {description} {acceptance_criteria}".lower()

        abuse_cases = []
        stride_threats = {cat["id"]: [] for cat in self.STRIDE_CATEGORIES}
        security_requirements = []
        risk_factors = []
        risk_score = 30  # Base risk score

        # Detect patterns and generate analysis
        patterns = self._detect_patterns(full_text)

        req_counter = 1
        abuse_counter = 1

        for pattern in patterns:
            # Add abuse cases
            for abuse in pattern.get("abuse_cases", []):
                abuse_cases.append({
                    "id": f"AC-{abuse_counter:03d}",
                    "title": abuse["title"],
                    "description": abuse["description"],
                    "threat_actor": abuse.get("threat_actor", "External Attacker"),
                    "impact": abuse.get("impact", "medium"),
                    "likelihood": abuse.get("likelihood", "medium")
                })
                abuse_counter += 1

            # Add STRIDE threats
            for stride_cat, threats in pattern.get("stride_threats", {}).items():
                for threat in threats:
                    stride_threats[stride_cat].append({
                        "id": f"{stride_cat}-{len(stride_threats[stride_cat]) + 1:03d}",
                        "threat": threat["threat"],
                        "mitigation": threat["mitigation"]
                    })

            # Add security requirements
            for req in pattern.get("requirements", []):
                security_requirements.append({
                    "id": f"SR-{req_counter:03d}",
                    "category": req["category"],
                    "requirement": req["requirement"],
                    "priority": req.get("priority", "should"),
                    "rationale": req.get("rationale", "Security best practice"),
                    "acceptance_criteria": req.get("acceptance_criteria", "Verified through security testing")
                })
                req_counter += 1

            # Add risk factors
            if pattern.get("risk_factor"):
                risk_factors.append(pattern["risk_factor"])
                risk_score += pattern["risk_factor"]["score"]

        # Ensure we have at least some baseline requirements
        if not security_requirements:
            security_requirements = self._get_baseline_requirements()

        risk_score = min(100, risk_score)

        return {
            "abuse_cases": abuse_cases,
            "stride_threats": stride_threats,
            "security_requirements": security_requirements,
            "risk_score": risk_score,
            "risk_factors": risk_factors
        }

    def _detect_patterns(self, text: str) -> List[Dict]:
        """Detect security-relevant patterns in text"""
        patterns = []

        # Authentication patterns
        auth_keywords = ["login", "sign in", "authenticate", "password", "credential", "user account"]
        if any(kw in text for kw in auth_keywords):
            patterns.append({
                "abuse_cases": [
                    {
                        "title": "Account Sharing for Subscription Abuse",
                        "description": "â€¢ User shares login credentials with friends/family to avoid paying for additional licenses\nâ€¢ Multiple people access same account from different locations and devices\nâ€¢ Business loses revenue from unpaid subscriptions\nâ€¢ Usage patterns show impossible geographic access (login from US, then India within minutes)\nâ€¢ May violate terms of service but users see it as harmless sharing\nâ€¢ Similar to Netflix password sharing problem affecting millions in revenue",
                        "threat_actor": "Regular User / Cost-Conscious Customer",
                        "impact": "High",
                        "likelihood": "High",
                        "stride_category": "Repudiation",
                        "mitigations": [
                            "Implement concurrent session limits based on subscription tier",
                            "Alert users when login detected from new device/location",
                            "Offer family/team plans at reasonable price points",
                            "Add friction for suspicious access patterns (verification required)",
                            "Monitor and analyze multi-device usage patterns"
                        ]
                    },
                    {
                        "title": "Ex-Employee Retains System Access",
                        "description": "â€¢ Employee leaves company but account remains active due to offboarding gaps\nâ€¢ Former employee continues accessing internal systems, customer data, or proprietary information\nâ€¢ May download contacts, sales data, or code before joining competitor\nâ€¢ HR notifies IT but account deactivation is delayed or incomplete\nâ€¢ Similar to Cisco incident where former employee deleted 456 VMs after resignation",
                        "threat_actor": "Disgruntled Ex-Employee / Insider",
                        "impact": "Critical",
                        "likelihood": "Medium",
                        "stride_category": "Information Disclosure",
                        "mitigations": [
                            "Integrate HR system with identity provider for automated deprovisioning",
                            "Implement same-day account deactivation SLA upon termination notice",
                            "Require regular access reviews and attestation by managers",
                            "Log and alert on access from deactivated accounts",
                            "Implement data loss prevention for sensitive data exports"
                        ]
                    },
                    {
                        "title": "Customer Support Impersonation",
                        "description": "â€¢ Fraudster calls customer support pretending to be account holder\nâ€¢ Uses publicly available information (name, email, last purchase) to pass verification\nâ€¢ Convinces support agent to reset password, change email, or provide account access\nâ€¢ Gains full control of victim's account through social engineering\nâ€¢ Can make fraudulent purchases, steal rewards points, or access personal data\nâ€¢ Twitter hack (2020) used similar social engineering on support staff",
                        "threat_actor": "Fraudster / Social Engineer",
                        "impact": "High",
                        "likelihood": "Medium",
                        "stride_category": "Spoofing",
                        "mitigations": [
                            "Implement multi-factor verification for sensitive support requests",
                            "Train support staff on social engineering red flags",
                            "Require callback to registered phone for account changes",
                            "Add cooling-off period for email/password changes",
                            "Log all support interactions with account change audit trail"
                        ]
                    }
                ],
                "stride_threats": {
                    "S": [{"threat": "Attacker spoofs legitimate user identity through credential theft or session hijacking", "mitigation": "Implement MFA, device binding, and behavioral analysis"}],
                    "I": [{"threat": "Password or session token exposed in transit, logs, or client-side storage", "mitigation": "Use HTTPS only, never log credentials, use httpOnly cookies"}],
                    "E": [{"threat": "Privilege escalation via authentication bypass or role manipulation", "mitigation": "Implement proper RBAC with server-side validation, principle of least privilege"}]
                },
                "requirements": [
                    {
                        "category": "Authentication",
                        "requirement": "Implement adaptive rate limiting on all authentication endpoints",
                        "priority": "Critical",
                        "rationale": "â€¢ Prevents brute force and credential stuffing attacks that can compromise user accounts\nâ€¢ Mitigates CWE-307 (Improper Restriction of Excessive Authentication Attempts)\nâ€¢ Required by OWASP ASVS V2.2.1 and PCI-DSS Requirement 8.1.6\nâ€¢ Without this control, attackers can attempt millions of password combinations",
                        "acceptance_criteria": "â€¢ Rate limit of 5 failed attempts per minute per IP/username enforced\nâ€¢ Exponential backoff implemented after threshold exceeded\nâ€¢ Automated tests verify rate limiting blocks excessive attempts\nâ€¢ Monitoring alerts configured for rate limit triggers"
                    },
                    {
                        "category": "Authentication",
                        "requirement": "Enforce cryptographically secure password storage using Argon2id",
                        "priority": "Critical",
                        "rationale": "â€¢ Protects passwords even if database is compromised\nâ€¢ Argon2id is the winner of Password Hashing Competition, resistant to GPU/ASIC attacks\nâ€¢ Mitigates CWE-916 (Use of Password Hash With Insufficient Computational Effort)\nâ€¢ Required by OWASP ASVS V2.4.1 and NIST SP 800-63B",
                        "acceptance_criteria": "â€¢ All passwords hashed with Argon2id (memory=64MB, iterations=3, parallelism=4)\nâ€¢ No plaintext or weakly hashed passwords in database\nâ€¢ Password hash timing is constant regardless of input\nâ€¢ Unit tests verify hash generation and verification"
                    },
                    {
                        "category": "Authentication",
                        "requirement": "Implement account lockout with secure recovery mechanism",
                        "priority": "High",
                        "rationale": "â€¢ Stops brute force attacks by locking accounts after failed attempts\nâ€¢ Mitigates CWE-307 and reduces attack surface\nâ€¢ Balance security with usability through progressive lockout\nâ€¢ OWASP ASVS V2.2.1 compliance requirement",
                        "acceptance_criteria": "â€¢ Account locked after 5 consecutive failed attempts\nâ€¢ Lockout duration increases exponentially (15min, 1hr, 24hr)\nâ€¢ Secure unlock via email verification or admin intervention\nâ€¢ Lockout events logged with IP, timestamp, username"
                    },
                    {
                        "category": "Logging",
                        "requirement": "Comprehensive authentication event logging with SIEM integration",
                        "priority": "High",
                        "rationale": "â€¢ Enables detection of brute force, credential stuffing, and account takeover attempts\nâ€¢ Required for incident response and forensic analysis\nâ€¢ PCI-DSS Requirement 10.2 mandates logging of authentication events\nâ€¢ GDPR Article 33 requires breach detection capabilities",
                        "acceptance_criteria": "â€¢ All auth events logged: success, failure, lockout, unlock, password change\nâ€¢ Logs include timestamp, IP, user-agent, username, result, failure reason\nâ€¢ Logs forwarded to SIEM with alerting rules configured\nâ€¢ Log retention minimum 1 year, tamper-evident storage"
                    }
                ],
                "risk_factor": {"factor": "Authentication", "score": 25, "description": "Feature involves user authentication - primary target for attackers"}
            })

        # Payment/Financial patterns
        payment_keywords = ["payment", "credit card", "transaction", "purchase", "billing", "checkout"]
        if any(kw in text for kw in payment_keywords):
            patterns.append({
                "abuse_cases": [
                    {
                        "title": "Promo Code Stacking and Abuse",
                        "description": "â€¢ Savvy customer discovers multiple promo codes can be combined at checkout\nâ€¢ Shares working codes on deal forums (SlickDeals, Reddit) causing viral spread\nâ€¢ Thousands of customers exploit loophole before company notices\nâ€¢ Products sold below cost resulting in significant financial loss\nâ€¢ Company forced to cancel orders causing customer service nightmare\nâ€¢ Similar to Uber promo code abuse costing millions in free rides",
                        "threat_actor": "Bargain Hunter / Deal Community",
                        "impact": "High",
                        "likelihood": "High",
                        "stride_category": "Tampering",
                        "mitigations": [
                            "Enforce single promo code per order rule at checkout",
                            "Set usage limits per code (total uses, per-customer limit)",
                            "Implement minimum order value requirements for discounts",
                            "Monitor for sudden spikes in promo code usage",
                            "Add approval workflow for discounts exceeding threshold"
                        ]
                    },
                    {
                        "title": "Friendly Fraud / Chargeback Abuse",
                        "description": "â€¢ Customer makes legitimate purchase and receives product\nâ€¢ Files chargeback claiming item not received or unauthorized transaction\nâ€¢ Keeps both product and refund while merchant pays chargeback fee\nâ€¢ Repeat offenders create multiple accounts to continue abuse\nâ€¢ Costs merchants 2-3x the transaction value (product + refund + fees)\nâ€¢ Industry loses $40B+ annually to friendly fraud",
                        "threat_actor": "Dishonest Customer / Serial Refunder",
                        "impact": "High",
                        "likelihood": "High",
                        "stride_category": "Repudiation",
                        "mitigations": [
                            "Require signature on delivery for high-value orders",
                            "Maintain detailed proof of delivery with photos and GPS",
                            "Implement fraud scoring based on customer history",
                            "Flag accounts with previous chargeback history",
                            "Use 3D Secure to shift liability for disputed transactions"
                        ]
                    },
                    {
                        "title": "Refund Policy Exploitation",
                        "description": "â€¢ Customer purchases expensive item for one-time use (dress, camera, tools)\nâ€¢ Uses product for event or project, then returns claiming dissatisfaction\nâ€¢ Returns used/worn items within return window for full refund\nâ€¢ Some create fake receipts or swap expensive items with cheaper versions\nâ€¢ Retail industry loses $25B+ annually to return fraud\nâ€¢ Legitimate customers pay higher prices to offset losses",
                        "threat_actor": "Opportunistic Customer / Wardrobing Abuser",
                        "impact": "Medium",
                        "likelihood": "High",
                        "stride_category": "Repudiation",
                        "mitigations": [
                            "Implement return limits per customer (3 returns per quarter)",
                            "Add non-removable tags that indicate item was used",
                            "Require original packaging and tags for full refund",
                            "Track and flag serial returners in customer database",
                            "Charge restocking fee for opened/used items"
                        ]
                    }
                ],
                "stride_threats": {
                    "T": [{"threat": "Transaction amount manipulation via request tampering", "mitigation": "Server-side price calculation with cryptographic cart signing"}],
                    "R": [{"threat": "User disputes legitimate transaction (friendly fraud)", "mitigation": "Comprehensive transaction logging with device fingerprint and IP"}],
                    "I": [{"threat": "Payment card data exposure via formjacking or database breach", "mitigation": "Use payment tokenization, never store full PAN, implement CSP"}]
                },
                "requirements": [
                    {
                        "category": "Data Protection",
                        "requirement": "Implement PCI-DSS compliant payment card handling using tokenization",
                        "priority": "Critical",
                        "rationale": "â€¢ PCI-DSS mandates protection of cardholder data (Requirement 3)\nâ€¢ Storing full card numbers exposes business to massive liability\nâ€¢ Tokenization removes PCI scope from application servers\nâ€¢ Breach of card data results in fines up to $500K and brand damage\nâ€¢ CWE-311 (Missing Encryption of Sensitive Data)",
                        "acceptance_criteria": "â€¢ No full card numbers stored in application database\nâ€¢ Payment processor tokenization (Stripe, Braintree) implemented\nâ€¢ PCI SAQ-A or SAQ-A-EP compliance achieved\nâ€¢ Quarterly ASV scans show no card data exposure"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Server-side validation of all transaction amounts with cryptographic integrity",
                        "priority": "Critical",
                        "rationale": "â€¢ Prevents price manipulation attacks that cause direct financial loss\nâ€¢ Client-side prices can be trivially modified via browser tools\nâ€¢ CWE-20 (Improper Input Validation)\nâ€¢ OWASP ASVS V5.1.3 requires server-side validation",
                        "acceptance_criteria": "â€¢ All prices retrieved from server-side product catalog at checkout\nâ€¢ Cart contents signed with HMAC, validated before payment processing\nâ€¢ Price discrepancies logged and flagged for review\nâ€¢ Automated tests verify price manipulation attempts are rejected"
                    },
                    {
                        "category": "Logging",
                        "requirement": "Comprehensive financial transaction audit trail with tamper-evident storage",
                        "priority": "Critical",
                        "rationale": "â€¢ Required for fraud investigation and chargeback disputes\nâ€¢ PCI-DSS Requirement 10 mandates transaction logging\nâ€¢ SOX compliance requires financial audit trails\nâ€¢ Essential for forensic analysis in breach scenarios",
                        "acceptance_criteria": "â€¢ All transactions logged: amount, timestamp, user, IP, device fingerprint, result\nâ€¢ Logs stored in append-only, tamper-evident storage\nâ€¢ Retention minimum 7 years for financial compliance\nâ€¢ Real-time alerting on suspicious transaction patterns"
                    },
                    {
                        "category": "Rate Limiting",
                        "requirement": "Implement anti-carding controls with velocity limits and bot detection",
                        "priority": "High",
                        "rationale": "â€¢ Prevents card testing fraud that leads to high chargebacks\nâ€¢ Payment processors may terminate accounts with >1% chargeback rate\nâ€¢ Automated carding attempts are easily detectable with proper controls\nâ€¢ CWE-799 (Improper Control of Interaction Frequency)",
                        "acceptance_criteria": "â€¢ Maximum 3 failed card attempts per session before CAPTCHA required\nâ€¢ IP-based velocity limits: 10 transactions per hour\nâ€¢ Bot detection integrated (reCAPTCHA Enterprise, DataDome)\nâ€¢ Fraud scoring integrated with payment processor"
                    }
                ],
                "risk_factor": {"factor": "Financial Data", "score": 30, "description": "Feature handles payment card data - highest risk category"}
            })

        # Data input patterns
        input_keywords = ["form", "input", "submit", "upload", "enter", "search", "query"]
        if any(kw in text for kw in input_keywords):
            patterns.append({
                "abuse_cases": [
                    {
                        "title": "Search Results Scraping for Competitive Intelligence",
                        "description": "â€¢ Competitor creates script to systematically search and extract product catalog\nâ€¢ Queries every product category to build complete inventory database\nâ€¢ Uses extracted data to undercut pricing or copy product descriptions\nâ€¢ Causes increased server load and bandwidth costs\nâ€¢ Business loses competitive advantage from proprietary data\nâ€¢ Similar to LinkedIn vs hiQ Labs data scraping lawsuit",
                        "threat_actor": "Competitor / Data Aggregator",
                        "impact": "Medium",
                        "likelihood": "High",
                        "stride_category": "Information Disclosure",
                        "mitigations": [
                            "Implement rate limiting on search endpoints (requests per minute)",
                            "Add CAPTCHA after unusual query volumes",
                            "Use robots.txt and legal terms to prohibit scraping",
                            "Monitor for bot-like access patterns (sequential queries, no mouse movement)",
                            "Consider requiring authentication for detailed product data"
                        ]
                    },
                    {
                        "title": "Form Spam and Fake Lead Generation",
                        "description": "â€¢ Spammers submit fake entries through contact forms, registration, or lead capture\nâ€¢ Fills database with junk data degrading data quality\nâ€¢ Sales team wastes time following up on fake leads\nâ€¢ May include malicious links or phishing content in message fields\nâ€¢ Competitors may submit fake leads to waste your resources\nâ€¢ Can affect email deliverability if spam triggers bounces",
                        "threat_actor": "Spammer / Competitor / Bot Network",
                        "impact": "Medium",
                        "likelihood": "High",
                        "stride_category": "Denial of Service",
                        "mitigations": [
                            "Implement invisible CAPTCHA (reCAPTCHA v3) on forms",
                            "Add honeypot fields that bots fill but humans ignore",
                            "Validate email addresses with confirmation step",
                            "Rate limit submissions per IP address",
                            "Use phone verification for high-value lead forms"
                        ]
                    },
                    {
                        "title": "Search Engine Manipulation via Keyword Stuffing",
                        "description": "â€¢ Users discover they can inject content through search or input fields\nâ€¢ Submits content designed to manipulate search engine rankings\nâ€¢ Adds hidden keywords, links to external sites, or competitor negative content\nâ€¢ Can damage brand reputation if malicious content appears in search results\nâ€¢ May violate search engine guidelines resulting in ranking penalties\nâ€¢ User-generated content becomes liability without proper moderation",
                        "threat_actor": "SEO Spammer / Competitor",
                        "impact": "Medium",
                        "likelihood": "Medium",
                        "stride_category": "Tampering",
                        "mitigations": [
                            "Implement content moderation for user-submitted text",
                            "Add nofollow/noindex to user-generated content pages",
                            "Filter or escape HTML tags in user inputs",
                            "Monitor for unusual patterns in submitted content",
                            "Implement reporting mechanism for inappropriate content"
                        ]
                    }
                ],
                "stride_threats": {
                    "T": [{"threat": "SQL/NoSQL injection allowing data modification or deletion", "mitigation": "Parameterized queries, input validation, least privilege DB accounts"}],
                    "I": [{"threat": "Data extraction via injection attacks or XSS", "mitigation": "Output encoding, CSP, parameterized queries"}],
                    "E": [{"threat": "Command injection leading to server compromise", "mitigation": "Avoid system commands, use native libraries, sandboxing"}]
                },
                "requirements": [
                    {
                        "category": "Input Validation",
                        "requirement": "Implement comprehensive input validation with whitelist approach",
                        "priority": "Critical",
                        "rationale": "â€¢ First line of defense against injection attacks (SQL, XSS, Command)\nâ€¢ CWE-20 (Improper Input Validation) is root cause of most vulnerabilities\nâ€¢ OWASP ASVS V5.1 requires input validation\nâ€¢ Whitelist validation is more secure than blacklist (blocklist bypass techniques exist)",
                        "acceptance_criteria": "â€¢ All inputs validated against expected type, length, format, and range\nâ€¢ Validation occurs server-side (client-side is insufficient)\nâ€¢ Unexpected input rejected with generic error message\nâ€¢ SAST tools report zero input validation findings"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Use parameterized queries exclusively for all database operations",
                        "priority": "Critical",
                        "rationale": "â€¢ Prevents SQL injection by separating code from data\nâ€¢ CWE-89 (SQL Injection) consistently in OWASP Top 10\nâ€¢ OWASP ASVS V5.3.4 mandates parameterized queries\nâ€¢ ORM usage provides additional abstraction but must still use parameters",
                        "acceptance_criteria": "â€¢ Zero string concatenation in SQL queries verified by code review\nâ€¢ All database access uses ORM or prepared statements\nâ€¢ SQLMap scan shows no SQL injection vulnerabilities\nâ€¢ SAST rules for SQL injection show no findings"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Implement context-aware output encoding for XSS prevention",
                        "priority": "Critical",
                        "rationale": "â€¢ Prevents XSS by encoding output based on context (HTML, JS, URL, CSS)\nâ€¢ CWE-79 (Cross-Site Scripting) affects millions of applications\nâ€¢ OWASP ASVS V5.3.3 requires output encoding\nâ€¢ Modern frameworks provide auto-escaping but developers can bypass it",
                        "acceptance_criteria": "â€¢ All user-controlled output encoded appropriately for context\nâ€¢ CSP deployed with strict script-src (no unsafe-inline)\nâ€¢ DOM XSS sinks identified and protected\nâ€¢ DAST scan shows no XSS vulnerabilities"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Implement input length and complexity limits",
                        "priority": "High",
                        "rationale": "â€¢ Prevents buffer overflow, ReDoS, and resource exhaustion attacks\nâ€¢ CWE-400 (Resource Exhaustion) via oversized inputs\nâ€¢ Limits attack surface for injection attempts\nâ€¢ OWASP ASVS V5.1.3 requires length validation",
                        "acceptance_criteria": "â€¢ Maximum length defined for all input fields\nâ€¢ Regex patterns validated for catastrophic backtracking\nâ€¢ Large inputs rejected before processing\nâ€¢ Load tests verify no DoS via large inputs"
                    }
                ],
                "risk_factor": {"factor": "User Input", "score": 20, "description": "Feature accepts user input - primary attack vector"}
            })

        # File upload patterns
        if "upload" in text or "file" in text:
            patterns.append({
                "abuse_cases": [
                    {
                        "title": "Web Shell Upload via File Type Bypass",
                        "description": "â€¢ Attacker uploads executable script disguised with innocent extension (shell.php.jpg)\nâ€¢ Exploits weak validation that only checks file extension or trusts MIME type\nâ€¢ Accesses uploaded file directly to execute arbitrary commands on server\nâ€¢ Gains remote code execution with web application's privileges\nâ€¢ Can install persistent backdoors, create admin accounts, or exfiltrate data\nâ€¢ Average breach cost exceeds $4M including incident response and regulatory fines",
                        "threat_actor": "External Attacker",
                        "impact": "Critical",
                        "likelihood": "High",
                        "stride_category": "Elevation of Privilege",
                        "mitigations": [
                            "Validate file type using magic bytes, not extension or MIME type",
                            "Store uploads outside web root with randomized filenames",
                            "Serve files with Content-Disposition: attachment header",
                            "Implement antivirus scanning (ClamAV) on all uploads",
                            "Use separate domain for user content with no script execution",
                            "Re-encode images to remove any embedded executable code"
                        ]
                    },
                    {
                        "title": "Path Traversal via Filename Manipulation",
                        "description": "â€¢ Attacker crafts filename with directory traversal sequences (../../../)\nâ€¢ Bypasses upload directory restrictions to write files anywhere on filesystem\nâ€¢ Can overwrite application files, configuration, or system files\nâ€¢ May achieve remote code execution by overwriting executable content\nâ€¢ Results in data destruction, configuration tampering, or complete compromise\nâ€¢ Indicates fundamental flaw in file handling implementation",
                        "threat_actor": "External Attacker",
                        "impact": "Critical",
                        "likelihood": "Medium",
                        "stride_category": "Tampering",
                        "mitigations": [
                            "Generate server-side filenames (UUID), never use client-provided names",
                            "Sanitize filenames by removing path separators and special characters",
                            "Validate resolved path is within intended upload directory",
                            "Use containerization to limit filesystem access scope",
                            "Set restrictive permissions on upload directory",
                            "Log all file operations with original and sanitized filenames"
                        ]
                    },
                    {
                        "title": "Denial of Service via Resource Exhaustion",
                        "description": "â€¢ Attacker floods upload endpoint with maximum-size files repeatedly\nâ€¢ May use zip bombs that expand to massive sizes during processing\nâ€¢ Exhausts disk space, memory, or processing capacity\nâ€¢ Causes service unavailability for legitimate users\nâ€¢ Results in infrastructure costs and SLA violations\nâ€¢ Can be automated for sustained attack with minimal attacker resources",
                        "threat_actor": "External Attacker / Competitor",
                        "impact": "High",
                        "likelihood": "Medium",
                        "stride_category": "Denial of Service",
                        "mitigations": [
                            "Enforce file size limits at web server level (10MB default)",
                            "Use streaming processing to reject oversized files early",
                            "Implement per-user and per-IP upload quotas",
                            "Detect archive bombs by limiting decompression ratio",
                            "Use separate storage volume with quota limits",
                            "Apply rate limiting on upload endpoints"
                        ]
                    }
                ],
                "stride_threats": {
                    "T": [{"threat": "Malicious file execution or system file overwrite via path traversal", "mitigation": "Magic byte validation, server-generated filenames, canonical path checks"}],
                    "D": [{"threat": "Storage/resource exhaustion via large or malicious uploads", "mitigation": "Size limits, quotas, zip bomb detection"}],
                    "E": [{"threat": "Remote code execution via web shell upload", "mitigation": "Store outside web root, no execute permissions, malware scanning"}]
                },
                "requirements": [
                    {
                        "category": "Input Validation",
                        "requirement": "Validate file types using magic bytes and content inspection",
                        "priority": "Critical",
                        "rationale": "â€¢ File extension and MIME type can be trivially spoofed by attackers\nâ€¢ Magic bytes (file signatures) provide reliable file type identification\nâ€¢ CWE-434 (Unrestricted Upload of File with Dangerous Type)\nâ€¢ OWASP ASVS V12.1.1 requires file type validation",
                        "acceptance_criteria": "â€¢ File type validated by reading first bytes and comparing to known signatures\nâ€¢ Whitelist of allowed file types enforced (not blacklist)\nâ€¢ Content inspection performed for complex formats (images re-encoded)\nâ€¢ Automated tests verify dangerous file types are rejected"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Implement malware scanning on all uploaded files",
                        "priority": "High",
                        "rationale": "â€¢ Uploaded files may contain malware that affects other users or systems\nâ€¢ Defense in depth against novel file-based attacks\nâ€¢ CWE-434 mitigation\nâ€¢ Required for handling user-generated content at scale",
                        "acceptance_criteria": "â€¢ All uploads scanned with antivirus (ClamAV or commercial solution)\nâ€¢ Infected files quarantined and logged\nâ€¢ Scan results available within acceptable latency\nâ€¢ Signature database updated automatically"
                    },
                    {
                        "category": "Input Validation",
                        "requirement": "Enforce file size limits and upload quotas",
                        "priority": "High",
                        "rationale": "â€¢ Prevents denial of service via storage exhaustion\nâ€¢ CWE-400 (Uncontrolled Resource Consumption)\nâ€¢ Protects infrastructure costs and performance\nâ€¢ OWASP ASVS V12.1.2 requires size limits",
                        "acceptance_criteria": "â€¢ Maximum file size enforced at web server level (10MB default)\nâ€¢ Per-user storage quota implemented and enforced\nâ€¢ Oversized uploads rejected before full transfer completes\nâ€¢ Archive bomb detection rejects files with high compression ratio"
                    },
                    {
                        "category": "Data Protection",
                        "requirement": "Store uploaded files outside web root with restricted access",
                        "priority": "Critical",
                        "rationale": "â€¢ Prevents direct execution of uploaded malicious scripts\nâ€¢ Defense in depth against file type validation bypass\nâ€¢ CWE-434 mitigation\nâ€¢ OWASP ASVS V12.3.1 requires secure file storage",
                        "acceptance_criteria": "â€¢ Upload directory is outside document root\nâ€¢ Files served through application handler, not direct URL\nâ€¢ No execute permissions on upload directory\nâ€¢ Files served with Content-Disposition: attachment header"
                    }
                ],
                "risk_factor": {"factor": "File Upload", "score": 25, "description": "Feature allows file uploads - high risk for RCE"}
            })

        # API patterns
        api_keywords = ["api", "endpoint", "rest", "graphql", "webhook"]
        if any(kw in text for kw in api_keywords):
            patterns.append({
                "abuse_cases": [
                    {
                        "title": "Broken Object Level Authorization (BOLA/IDOR)",
                        "description": "â€¢ Attacker manipulates resource IDs in API requests to access other users' data\nâ€¢ Changes /api/users/123/orders to /api/users/124/orders to view another user's orders\nâ€¢ API returns data without verifying the requestor owns the requested resource\nâ€¢ Can enumerate through sequential IDs to extract data at scale\nâ€¢ Results in mass data exposure and privacy violations\nâ€¢ BOLA is the #1 API vulnerability according to OWASP API Security Top 10",
                        "threat_actor": "External Attacker / Malicious User",
                        "impact": "Critical",
                        "likelihood": "High",
                        "stride_category": "Information Disclosure",
                        "mitigations": [
                            "Implement object-level authorization on every API endpoint",
                            "Use indirect references instead of direct database IDs",
                            "Verify resource ownership against authenticated user context",
                            "Use UUIDs instead of sequential IDs to prevent enumeration",
                            "Add automated BOLA testing to CI/CD pipeline",
                            "Monitor and alert on unusual access patterns"
                        ]
                    },
                    {
                        "title": "API Rate Limiting Bypass and Abuse",
                        "description": "â€¢ Attacker identifies rate limiting gaps by testing request volumes\nâ€¢ Bypasses limits using IP rotation, API key cycling, or header manipulation\nâ€¢ Overwhelms API causing service degradation for legitimate users\nâ€¢ May scrape entire databases through paginated endpoints\nâ€¢ Results in infrastructure costs and potential data theft\nâ€¢ Causes SLA violations and customer impact",
                        "threat_actor": "External Attacker / Automated Bot",
                        "impact": "High",
                        "likelihood": "High",
                        "stride_category": "Denial of Service",
                        "mitigations": [
                            "Implement tiered rate limiting: per-IP, per-user, per-API-key",
                            "Use token bucket or sliding window rate limiting algorithms",
                            "Deploy API gateway with DDoS protection",
                            "Implement request signing to prevent replay attacks",
                            "Monitor and alert on unusual traffic patterns",
                            "Add CAPTCHA for sensitive operations after threshold"
                        ]
                    },
                    {
                        "title": "Mass Assignment / Excessive Data Exposure",
                        "description": "â€¢ Attacker adds unauthorized fields to API requests (role, permissions, balance)\nâ€¢ API blindly binds request body to database model without filtering\nâ€¢ Can escalate privileges by setting admin role or modify financial data\nâ€¢ API responses may expose sensitive fields not intended for client\nâ€¢ Results in unauthorized access and data integrity violations\nâ€¢ Indicates missing input validation and response filtering",
                        "threat_actor": "External Attacker / Malicious User",
                        "impact": "High",
                        "likelihood": "Medium",
                        "stride_category": "Tampering",
                        "mitigations": [
                            "Define explicit allowlist of modifiable fields per endpoint",
                            "Use DTOs/schemas with only intended fields (Pydantic, Marshmallow)",
                            "Never bind request body directly to database models",
                            "Remove sensitive fields from API responses",
                            "Implement field-level authorization for sensitive attributes",
                            "Document and security review all API fields"
                        ]
                    }
                ],
                "stride_threats": {
                    "S": [{"threat": "API key theft, JWT forgery, or authentication bypass", "mitigation": "Secure key storage, short-lived tokens, proper JWT validation"}],
                    "I": [{"threat": "Excessive data exposure in API responses or BOLA attacks", "mitigation": "Response filtering, object-level authorization, minimal data principle"}],
                    "D": [{"threat": "API abuse causing service degradation or cost explosion", "mitigation": "Multi-layer rate limiting, API gateway, DDoS protection"}]
                },
                "requirements": [
                    {
                        "category": "Authentication",
                        "requirement": "Implement secure API authentication using OAuth 2.0 or JWT",
                        "priority": "Critical",
                        "rationale": "â€¢ APIs are primary attack surface for modern applications\nâ€¢ OWASP API Security Top 10 - API2:2023 Broken Authentication\nâ€¢ JWT must be properly validated (signature, expiry, issuer, audience)\nâ€¢ API keys should be rotatable and have minimal scope",
                        "acceptance_criteria": "â€¢ All API endpoints require authentication except explicitly public ones\nâ€¢ JWT validation includes signature, expiry, issuer, and audience checks\nâ€¢ API keys are hashed in storage, rotatable, and audited\nâ€¢ Authentication failures return generic errors (no user enumeration)"
                    },
                    {
                        "category": "Authorization",
                        "requirement": "Implement object-level authorization on all data access endpoints",
                        "priority": "Critical",
                        "rationale": "â€¢ BOLA/IDOR is #1 API vulnerability (OWASP API Top 10 2023)\nâ€¢ Every request must verify user has access to requested resource\nâ€¢ CWE-639 (Authorization Bypass Through User-Controlled Key)\nâ€¢ Cannot rely solely on authentication - authorization is separate concern",
                        "acceptance_criteria": "â€¢ Every endpoint verifies resource ownership before returning data\nâ€¢ Automated BOLA tests in CI/CD pipeline\nâ€¢ Access denied for resources not owned by authenticated user\nâ€¢ Audit log captures all authorization decisions"
                    },
                    {
                        "category": "Rate Limiting",
                        "requirement": "Implement multi-layer API rate limiting with adaptive thresholds",
                        "priority": "High",
                        "rationale": "â€¢ Prevents DoS, brute force, and scraping attacks\nâ€¢ OWASP API Security Top 10 - API4:2023 Unrestricted Resource Consumption\nâ€¢ Protects infrastructure costs and availability\nâ€¢ CWE-770 (Allocation of Resources Without Limits)",
                        "acceptance_criteria": "â€¢ Rate limits enforced per-IP, per-user, and per-API-key\nâ€¢ Limits documented in API specification\nâ€¢ 429 responses include Retry-After header\nâ€¢ Anomaly detection alerts on unusual patterns"
                    },
                    {
                        "category": "Logging",
                        "requirement": "Comprehensive API request/response logging with security context",
                        "priority": "High",
                        "rationale": "â€¢ Essential for incident detection and forensic analysis\nâ€¢ OWASP API Top 10 - API9:2023 Improper Inventory Management\nâ€¢ Required for compliance (PCI-DSS, SOC2)\nâ€¢ Enables threat hunting and anomaly detection",
                        "acceptance_criteria": "â€¢ All API calls logged with timestamp, user, IP, endpoint, response code\nâ€¢ Sensitive data redacted from logs (passwords, tokens, PII)\nâ€¢ Logs forwarded to SIEM with alerting rules\nâ€¢ Log retention meets compliance requirements"
                    }
                ],
                "risk_factor": {"factor": "API Exposure", "score": 20, "description": "Feature exposes API endpoints - significant attack surface"}
            })

        return patterns

    def _get_baseline_requirements(self) -> List[Dict]:
        """Return baseline security requirements"""
        return [
            {
                "id": "SR-001",
                "category": "Input Validation",
                "requirement": "All user inputs must be validated and sanitized",
                "priority": "must",
                "rationale": "Prevents injection attacks",
                "acceptance_criteria": "No raw user input reaches database or output"
            },
            {
                "id": "SR-002",
                "category": "Error Handling",
                "requirement": "Error messages must not expose sensitive information",
                "priority": "must",
                "rationale": "Prevents information disclosure",
                "acceptance_criteria": "Generic error messages shown to users"
            },
            {
                "id": "SR-003",
                "category": "Logging",
                "requirement": "Security-relevant events must be logged",
                "priority": "should",
                "rationale": "Enables security monitoring and incident response",
                "acceptance_criteria": "Audit logs capture who, what, when, where"
            }
        ]

    def _validate_and_enhance_result(self, result: Dict) -> Dict:
        """Validate and enhance AI-generated result to match securereq-ai format"""
        # Ensure all required fields exist
        if "abuse_cases" not in result:
            result["abuse_cases"] = []
        if "stride_threats" not in result:
            result["stride_threats"] = []
        if "security_requirements" not in result:
            result["security_requirements"] = self._get_baseline_requirements()
        if "risk_score" not in result:
            result["risk_score"] = 50

        # Normalize abuse cases - ensure consistent field names for Jira ADF builder
        for ac in result.get("abuse_cases", []):
            # Ensure both 'threat' and 'title' exist (ADF uses both)
            if "title" not in ac and "threat" in ac:
                ac["title"] = ac["threat"]
            if "threat" not in ac and "title" in ac:
                ac["threat"] = ac["title"]
            # Ensure 'actor' field exists (securereq-ai format)
            if "actor" not in ac and "threat_actor" in ac:
                ac["actor"] = ac["threat_actor"]
            if "threat_actor" not in ac and "actor" in ac:
                ac["threat_actor"] = ac["actor"]
            # Ensure mitigations is a list
            if "mitigations" not in ac:
                ac["mitigations"] = []
            elif isinstance(ac["mitigations"], str):
                ac["mitigations"] = [ac["mitigations"]]

        # Normalize security requirements - ensure both 'text' and 'requirement' exist
        for req in result.get("security_requirements", []):
            if "text" not in req and "requirement" in req:
                req["text"] = req["requirement"]
            if "requirement" not in req and "text" in req:
                req["requirement"] = req["text"]
            # Map 'details' to other fields for display
            if "details" in req:
                if "rationale" not in req:
                    req["rationale"] = req["details"]
                if "implementation_guidance" not in req:
                    req["implementation_guidance"] = req["details"]

        # Handle stride_threats - can be list (securereq-ai) or dict (old format)
        stride_threats = result.get("stride_threats", [])
        if isinstance(stride_threats, dict):
            # Convert dict format to list format for consistency
            threats_list = []
            for cat_id, threats in stride_threats.items():
                cat_name = {
                    "S": "Spoofing", "T": "Tampering", "R": "Repudiation",
                    "I": "Information Disclosure", "D": "Denial of Service", "E": "Elevation of Privilege"
                }.get(cat_id, cat_id)
                for threat in threats:
                    threats_list.append({
                        "category": cat_name,
                        "threat": threat.get("threat", ""),
                        "description": threat.get("attack_scenario", threat.get("mitigation", "")),
                        "risk_level": "High"
                    })
            result["stride_threats"] = threats_list

        return result

    def map_to_compliance(self, requirements: List[Dict], standards: List[str] = None) -> List[Dict]:
        """Map security requirements to compliance standards"""
        if standards is None:
            standards = ["OWASP ASVS", "PCI-DSS"]

        mappings = []
        for req in requirements:
            category = req.get("category", "").lower()
            req_text = req.get("requirement", "").lower()

            for standard in standards:
                if standard not in self.COMPLIANCE_STANDARDS:
                    continue

                for control_id, control_title in self.COMPLIANCE_STANDARDS[standard].items():
                    relevance = self._calculate_relevance(category, req_text, control_title.lower())
                    if relevance > 0.3:
                        mappings.append({
                            "requirement_id": req["id"],
                            "requirement_text": req["requirement"],
                            "standard_name": standard,
                            "control_id": control_id,
                            "control_title": control_title,
                            "relevance_score": relevance,
                            "mapping_rationale": f"Requirement addresses {control_title}"
                        })

        return mappings

    def _calculate_relevance(self, category: str, req_text: str, control_title: str) -> float:
        """Calculate relevance score between requirement and control"""
        score = 0.0

        # Category matching
        category_map = {
            "authentication": ["authentication", "identity"],
            "authorization": ["access control", "restrict"],
            "input validation": ["validation", "sanitization", "encoding"],
            "data protection": ["data protection", "cryptography", "protect"],
            "logging": ["logging", "monitoring", "log"],
            "error handling": ["error", "handling"],
        }

        for cat_key, keywords in category_map.items():
            if cat_key in category:
                for kw in keywords:
                    if kw in control_title:
                        score += 0.4

        # Keyword matching in requirement text
        control_words = control_title.split()
        for word in control_words:
            if len(word) > 3 and word in req_text:
                score += 0.1

        return min(1.0, score)


# Global instance
security_analyzer = SecurityRequirementsAnalyzer()
